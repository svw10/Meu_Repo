### üìÇ Estrutura de Diret√≥rios

```text
Minhas Skills/
‚îî‚îÄ‚îÄ pesquisando-web/
    ‚îú‚îÄ‚îÄ SKILL.md
    ‚îú‚îÄ‚îÄ scripts/
    ‚îÇ   ‚îî‚îÄ‚îÄ test_search.py       # Teste r√°pido de pesquisa via terminal
    ‚îî‚îÄ‚îÄ snippets/
        ‚îú‚îÄ‚îÄ apify_client.ts      # Cliente tipado para o Apify
        ‚îî‚îÄ‚îÄ research_workflow.ts # Workflow Inngest (Search -> Scrape -> Summarize)



### 1. O C√©rebro (`Minhas Skills/pesquisando-web/SKILL.md`)

---
name: pesquisando-web
description: O Pesquisador. Usa Apify para realizar buscas no Google, scraping de sites e extra√ß√£o de dados estruturados. Orquestra a leitura e sumariza√ß√£o de conte√∫do externo.
version: 1.0.0
tags: [apify, scraping, crawler, research, google]
---

# Pesquisando Web (Intelligence Protocol)

## üéØ Quando usar
- **D√∫vidas Factuais**: "Qual o pre√ßo atual do iPhone 15?"; "Quem √© o CEO da empresa X?".
- **Monitoramento**: "Verifique se saiu vaga nova no LinkedIn da Zenvia".
- **Enriquecimento**: O usu√°rio deu uma URL e quer um resumo.

## üß± Stack Vinculada
Esta skill √© um wrapper de intelig√™ncia sobre:
- **Apify**: O motor de execu√ß√£o (Actors: `google-search-scraper`, `website-content-crawler`).
- **Inngest**: Gerencia o tempo de espera (Scraping pode demorar 30s+).
- **OpenRouter**: L√™ o HTML sujo extra√≠do e transforma em Resumo Limpo.

## ‚öôÔ∏è Fluxo de Trabalho

- [ ] **1. Defini√ß√£o do Alvo**
    - √â uma busca geral? -> Use `google-search-scraper`.
    - √â um site espec√≠fico? -> Use `website-content-crawler`.
    - √â uma rede social? -> Use Actors espec√≠ficos (Instagram/LinkedIn Scrapers).

- [ ] **2. Execu√ß√£o Ass√≠ncrona (Apify + Inngest)**
    - O agente nunca deve travar a thread esperando o site carregar.
    - Dispare o job no Apify e aguarde o Webhook ou fa√ßa polling via Inngest (`step.waitForEvent` ou `step.sleep`).

- [ ] **3. Processamento e Limpeza**
    - O Apify devolve muito lixo (HTML, scripts).
    - Use o LLM (OpenRouter) para filtrar apenas o texto relevante antes de mostrar ao usu√°rio.

## üìã Checklist de Custo e Performance
- [ ] O Actor escolhido √© o mais barato para a tarefa? (Ex: Cheerio √© mais barato que Puppeteer).
- [ ] Limitou o n√∫mero de resultados (`maxItems`)? N√£o traga a internet inteira.

## üíª Snippets e Recursos

### Snippet 1: Disparo de Pesquisa (Exemplo Conceitual)
```typescript
await inngest.send({
  name: "app/research.start",
  data: {
    query: "Tend√™ncias de Micro-SaaS 2026",
    depth: "deep" // deep = l√™ o conte√∫do dos sites; fast = s√≥ l√™ os t√≠tulos do Google
  }
});


---

### 2. Snippets de Produ√ß√£o

#### `snippets/apify_client.ts` (O Bra√ßo Mec√¢nico)
Configura√ß√£o segura do cliente Apify para usar no seu Next.js.

```typescript
import { ApifyClient } from 'apify-client';

// Singleton para n√£o criar m√∫ltiplas conex√µes
const apify = new ApifyClient({
    token: process.env.APIFY_API_TOKEN,
});

export async function googleSearch(query: string, maxResults = 5) {
    // Usa o Google Search Scraper oficial
    const input = {
        queries: query,
        resultsPerPage: maxResults,
        maxPagesPerQuery: 1,
    };

    // Inicia e espera terminar (para buscas r√°pidas)
    const run = await apify.actor("apify/google-search-scraper").call(input);
    
    // Pega os resultados do Dataset
    const { items } = await apify.dataset(run.defaultDatasetId).listItems();
    return items;
}

export async function scrapeUrl(url: string) {
    // Usa o Cheerio (mais leve/r√°pido) para ler o texto da p√°gina
    const run = await apify.actor("apify/cheerio-scraper").call({
        startUrls: [{ url }],
        maxRequestsPerCrawl: 1,
    });

    const { items } = await apify.dataset(run.defaultDatasetId).listItems();
    return items[0]; // Retorna o conte√∫do da primeira URL
}


#### `snippets/research_workflow.ts` (O C√©rebro da Pesquisa no Inngest)

Este workflow faz o trabalho pesado: Busca no Google -> Entra nos Sites -> Resume o que encontrou.

import { inngest } from "@/inngest/client";
import { googleSearch, scrapeUrl } from "./apify_client";
import { generateSummary } from "@/lib/llm"; // Sua fun√ß√£o do OpenRouter

export const researchWorkflow = inngest.createFunction(
  { id: "web-researcher", concurrency: 5 },
  { event: "app/research.start" },
  async ({ event, step }) => {
    
    const { query } = event.data;

    // 1. Buscar Links no Google
    const searchResults = await step.run("google-search", async () => {
      return await googleSearch(query, 3);
    });

    // 2. Ler o conte√∫do de cada link (Paralelo)
    const contents = await step.run("scrape-contents", async () => {
      // Mapeia os 3 primeiros links e faz scraping
      const promises = searchResults.slice(0, 3).map(result => 
        scrapeUrl(result.url).catch(e => ({ error: true }))
      );
      return await Promise.all(promises);
    });

    // 3. Sintetizar Resposta com LLM
    const finalReport = await step.run("summarize-findings", async () => {
      const fullText = contents.map(c => c.text || "").join("\n\n");
      return await generateSummary(`Resuma isto baseado na query '${query}':\n${fullText}`);
    });

    // 4. Salvar na Mem√≥ria (Opcional, chama a skill de mem√≥ria)
    // await step.invoke("save-memory", { content: finalReport, tags: "research" });

    return { report: finalReport };
  }
);



### 3. Script de Teste R√°pido (`scripts/test_search.py`)

Para testar se sua chave Apify est√° funcionando sem subir o servidor inteiro.

import os
from apify_client import ApifyClient

# Requer: pip install apify-client
TOKEN = os.getenv("APIFY_API_TOKEN")

if not TOKEN:
    print("‚ùå APIFY_API_TOKEN n√£o encontrado no ambiente.")
    exit(1)

client = ApifyClient(token=TOKEN)

def test_google(query):
    print(f"üîé Pesquisando no Google via Apify: '{query}'...")
    
    # Input para o Google Search Scraper
    run_input = {
        "queries": query,
        "maxPagesPerQuery": 1,
        "resultsPerPage": 3,
    }

    # Executa o Actor
    run = client.actor("apify/google-search-scraper").call(run_input)
    
    print("‚úÖ Busca conclu√≠da! Extraindo resultados...")
    
    # Lista resultados
    for item in client.dataset(run["defaultDatasetId"]).iterate_items():
        title = item.get("title", "Sem t√≠tulo")
        link = item.get("url", "Sem link")
        print(f"- {title}\n  üîó {link}\n")

if __name__ == "__main__":
    test_google("Zenvia micro-saas trends")

